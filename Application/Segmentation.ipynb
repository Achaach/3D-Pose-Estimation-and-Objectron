{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53a89af",
   "metadata": {},
   "source": [
    "# Segementation\n",
    "\n",
    "One  broad application of object detection is segmentation. By using MediaPipe, we can do a Selfie Segmentation, the important people in the scene are divided up. Both PCs and smartphones are capable of running it in real-time. The targeted use cases involve video conferencing and selfie effects when the subject is close to the camera (less than two meters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3928ad69",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b43af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ff145",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "A selfie segmentation subgraph from the selfie segmentation module is used in the pipeline's implementation as a MediaPipe graph.\n",
    "\n",
    "### Model\n",
    "There two models, general and landscape. Both models are based on `MobileNetV3`, with modifications to make them more efficient. The general model operates on a `256x256x3 (HWC)` tensor, and outputs a `256x256x1` tensor representing the segmentation mask. The landscape model is similar to the general model, but operates on a `144x256x3(HWC)` tensor. It has fewer FLOPs than the general model, and therefore, runs faster. Note that MediaPipe Selfie Segmentation automatically resizes the input image to the desired tensor dimension before feeding it into the ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "BG_COLOR = (192, 192, 192) # gray\n",
    "MASK_COLOR = (255, 255, 255) # white\n",
    "with mp_selfie_segmentation.SelfieSegmentation(\n",
    "    model_selection=0) as selfie_segmentation:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = selfie_segmentation.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw selfie segmentation on the background image.\n",
    "    # To improve segmentation around boundaries, consider applying a joint\n",
    "    # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
    "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "    # Generate solid color images for showing the output selfie segmentation mask.\n",
    "    fg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "    fg_image[:] = MASK_COLOR\n",
    "    bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "    bg_image[:] = BG_COLOR\n",
    "    output_image = np.where(condition, fg_image, bg_image)\n",
    "    cv2.imwrite('/tmp/selfie_segmentation_output' + str(idx) + '.png', output_image)\n",
    "\n",
    "# For webcam input:\n",
    "BG_COLOR = (192, 192, 192) # gray\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_selfie_segmentation.SelfieSegmentation(\n",
    "    model_selection=1) as selfie_segmentation:\n",
    "  bg_image = None\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = selfie_segmentation.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw selfie segmentation on the background image.\n",
    "    # To improve segmentation around boundaries, consider applying a joint\n",
    "    # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
    "    condition = np.stack(\n",
    "      (results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "    # The background can be customized.\n",
    "    #   a) Load an image (with the same width and height of the input image) to\n",
    "    #      be the background, e.g., bg_image = cv2.imread('/path/to/image/file')\n",
    "    #   b) Blur the input image by applying image filtering, e.g.,\n",
    "    #      bg_image = cv2.GaussianBlur(image,(55,55),0)\n",
    "    if bg_image is None:\n",
    "      bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "      bg_image[:] = BG_COLOR\n",
    "    output_image = np.where(condition, image, bg_image)\n",
    "\n",
    "    cv2.imshow('MediaPipe Selfie Segmentation', output_image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85315ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
